# ğŸŒ OmniDoc AI: Multilingual Intelligent Document Conversational Assistant

[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Powered by Hugging Face](https://img.shields.io/badge/ğŸ¤—-Hugging%20Face-yellow)](https://huggingface.co/)
[![LangChain](https://img.shields.io/badge/ğŸ¦œ-LangChain-green)](https://langchain.com/)

A powerful multilingual conversational AI that can read, understand, and interact with any kind of document, including PDFs with scanned images, text documents, research papers, resumes, and reports. Built with LangChain and Hugging Face APIs, featuring OCR support, multilingual embeddings, contextual document classification, and dynamic response generation.

---

## ğŸŒŸ Key Features

### Core Capabilities

- **ğŸŒ Universal Document Support**: Process PDF, DOCX, TXT, CSV, XLSX, PPTX, JPG, PNG files
- **ğŸ‘ï¸ Intelligent OCR**: Automatic text extraction from scanned documents and images using TrOCR
- **ğŸŒ Multilingual Support**: 
  - Support for 100+ languages
  - Focus on Indian languages: Hindi, Tamil, Telugu, Bengali, Marathi, Gujarati, Kannada, Malayalam, Punjabi, Urdu
  - Cross-language queries (ask in Spanish, get answer from English document)
  - Automatic language detection and translation
- **ğŸ§  Context-Aware Intelligence**: Adapts behavior based on document type
  - Resume/CV analysis
  - Research paper summarization
  - Legal document simplification
  - Invoice/financial report extraction
  - Textbook content explanation
- **ğŸ” Advanced RAG**: Retrieval-Augmented Generation with multilingual embeddings
- **ğŸ’¡ Auto-Generated Insights**: Summaries, key points, and suggested questions
- **ğŸ“Š Document Classification**: Zero-shot classification into 6+ categories
- **ğŸ”’ Privacy-Aware**: PII detection and masking
- **ğŸ’¬ Conversational Memory**: Follow-up questions with context awareness
- **ğŸ“š Source Citations**: Transparent answers with document references

---

## ğŸš€ Quick Start

### Prerequisites

- Python 3.8 or higher
- Hugging Face API key (free tier available)

### Installation

1. **Clone the repository**
```bash
git clone <repository-url>
cd rag
```

2. **Create virtual environment** (recommended)
```bash
python -m venv venv
# Windows
venv\Scripts\activate
# Linux/Mac
source venv/bin/activate
```

3. **Install dependencies**
```bash
pip install -r requirements.txt
```

4. **Set up environment variables**
```bash
# Copy the example env file
copy .env.example .env

# Edit .env and add your Hugging Face API key
# Get your key from: https://huggingface.co/settings/tokens
```

5. **Run the application**
```bash
python app.py
```

6. **Open your browser**
Navigate to `http://localhost:7860`

---

## âš™ï¸ Configuration

### Environment Variables

Edit the `.env` file to configure the application:

```env
# Required: Your Hugging Face API Key
HUGGINGFACE_API_KEY=your_api_key_here

# Model Configuration (Optional - defaults provided)
EMBEDDING_MODEL=sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
LLM_MODEL=tiiuae/falcon-7b-instruct
OCR_MODEL=microsoft/trocr-base-printed
CLASSIFICATION_MODEL=facebook/bart-large-mnli
LANGUAGE_DETECTION_MODEL=papluca/xlm-roberta-base-language-detection
TRANSLATION_MODEL=Helsinki-NLP/opus-mt-mul-en

# Application Settings (Optional)
MAX_UPLOAD_SIZE_MB=50
CHUNK_SIZE=500
CHUNK_OVERLAP=50
TOP_K_RETRIEVAL=3
```

### Getting a Hugging Face API Key

1. Go to [Hugging Face](https://huggingface.co/)
2. Sign up for a free account
3. Navigate to [Settings â†’ Access Tokens](https://huggingface.co/settings/tokens)
4. Create a new token with "Read" permission
5. Copy the token to your `.env` file

---

## ğŸ“– Usage Guide

### Basic Workflow

1. **Upload Documents**
   - Click "Upload Files" and select one or multiple documents
   - Supported formats: PDF, DOCX, TXT, CSV, XLSX, PPTX, JPG, PNG
   - Click "Process Documents"

2. **Review Auto-Generated Insights**
   - Document type classification
   - Language detection
   - Summary and key points
   - Suggested questions

3. **Ask Questions**
   - Type your question in any language
   - Enable/disable translation as needed
   - View answers with source citations

4. **Follow-Up Questions**
   - Ask follow-up questions referencing previous answers
   - Conversation memory maintains context

### Example Use Cases

#### ğŸ“„ Resume Analysis
```
Upload: resume.pdf
Ask: "What are the candidate's top 5 skills?"
Ask: "How many years of Python experience does this person have?"
Ask: "Summarize the candidate's work history"
```

#### ğŸ“š Research Paper Understanding
```
Upload: research_paper.pdf
Ask: "What is the main research question?"
Ask: "Explain the methodology used"
Ask: "What are the key findings?"
```

#### ğŸ“– Scanned Textbook
```
Upload: scanned_chapter.jpg
Ask: "What are the main concepts covered?"
Ask: "Explain the first example"
Ask: "List all the definitions"
```

#### ğŸŒ Multilingual Queries
```
Upload: english_document.pdf
Ask in Hindi: "à¤‡à¤¸ à¤¦à¤¸à¥à¤¤à¤¾à¤µà¥‡à¤œà¤¼ à¤•à¤¾ à¤¸à¤¾à¤°à¤¾à¤‚à¤¶ à¤•à¥à¤¯à¤¾ à¤¹à¥ˆ?"
Get answer in Hindi based on English document
```

#### ğŸ“Š Invoice Processing
```
Upload: invoice.pdf
Ask: "What is the total amount?"
Ask: "Who is the vendor?"
Ask: "When is the payment due?"
```

---

## ğŸ—ï¸ Architecture

### System Components

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Gradio UI (app.py)                   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                     â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                         â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Document     â”‚    â”‚   Multilingual      â”‚
â”‚   Processor    â”‚    â”‚   Processor         â”‚
â”‚  (pipeline.py) â”‚    â”‚ (multilingual.py)   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
        â”‚                        â”‚
        â”‚             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚             â”‚   RAG Engine        â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚  (rag_engine.py)    â”‚
                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                      â”‚  Advanced Features  â”‚
                      â”‚ (advanced_features) â”‚
                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                 â”‚
                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                      â”‚  Hugging Face APIs  â”‚
                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Data Flow

1. **Document Upload** â†’ `DocumentProcessor` extracts text (with OCR if needed)
2. **Classification** â†’ Zero-shot classifier determines document type
3. **Language Detection** â†’ Identifies document language
4. **Chunking & Embedding** â†’ Text split into chunks, multilingual embeddings generated
5. **Vector Storage** â†’ FAISS index stores embeddings
6. **Query Processing**:
   - Detect query language
   - Translate if needed
   - Retrieve relevant chunks
   - Generate context-aware prompt
   - Call LLM for answer
   - Translate answer back if needed

---

## ğŸ”§ Technical Details

### Models Used

| Component | Model | Purpose |
|-----------|-------|---------|
| **Embeddings** | `sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2` | Multilingual semantic search |
| **LLM** | `tiiuae/falcon-7b-instruct` | Answer generation |
| **OCR** | `microsoft/trocr-base-printed` | Text extraction from images |
| **Classification** | `facebook/bart-large-mnli` | Document type classification |
| **Language Detection** | `papluca/xlm-roberta-base-language-detection` | Auto-detect input language |
| **Translation** | `Helsinki-NLP/opus-mt-*` | Cross-language translation |

### Key Technologies

- **LangChain**: RAG orchestration and text processing
- **Hugging Face**: API access to state-of-the-art models
- **FAISS**: Fast similarity search for vector retrieval
- **Gradio**: Interactive web interface
- **PyPDF2 & pdfplumber**: PDF text extraction
- **python-docx**: DOCX processing
- **Pillow**: Image processing

---

## ğŸ“ Project Structure

```
rag/
â”œâ”€â”€ app.py                    # Main Gradio application
â”œâ”€â”€ pipeline.py               # Document processing & OCR
â”œâ”€â”€ rag_engine.py            # RAG system with embeddings
â”œâ”€â”€ multilingual.py          # Language detection & translation
â”œâ”€â”€ advanced_features.py     # Question gen, PII masking, insights
â”œâ”€â”€ requirements.txt         # Python dependencies
â”œâ”€â”€ .env.example            # Environment variables template
â”œâ”€â”€ .gitignore              # Git ignore rules
â””â”€â”€ README.md               # This file
```

---

## ğŸ¯ Advanced Features

### 1. Automatic Question Generation
After uploading a document, the system suggests 5 relevant questions you can ask.

### 2. PII Detection and Masking
Automatically detects and masks:
- Email addresses
- Phone numbers
- Credit card numbers
- Dates
- Social security numbers

### 3. Context-Aware Prompting
Different prompt templates for:
- Resumes (focus on skills, experience)
- Research papers (focus on methodology, findings)
- Legal documents (simplify legal language)
- Invoices (focus on numbers, dates)
- Textbooks (educational explanations)

### 4. Document Comparison
Upload multiple documents and compare:
- Document types
- Size comparison
- Content themes

### 5. Conversation Memory
- Maintains last 10 interactions
- Allows follow-up questions
- Context-aware responses

### 6. Source Citations
Every answer includes:
- Source document name
- Page number
- Relevance score
- Content excerpt

---

## ğŸŒ Supported Languages

### Primary Support (with dedicated translation models)
- English
- Hindi (à¤¹à¤¿à¤¨à¥à¤¦à¥€)
- Tamil (à®¤à®®à®¿à®´à¯)
- Telugu (à°¤à±†à°²à±à°—à±)
- Bengali (à¦¬à¦¾à¦‚à¦²à¦¾)
- Marathi (à¤®à¤°à¤¾à¤ à¥€)
- Gujarati (àª—à«àªœàª°àª¾àª¤à«€)
- Kannada (à²•à²¨à³à²¨à²¡)
- Malayalam (à´®à´²à´¯à´¾à´³à´‚)
- Punjabi (à¨ªà©°à¨œà¨¾à¨¬à©€)
- Urdu (Ø§Ø±Ø¯Ùˆ)

### Additional Support
Spanish, French, German, Portuguese, Russian, Chinese, Japanese, Korean, Arabic, and 80+ more languages through multilingual embeddings.

---

## ğŸ› Troubleshooting

### Common Issues

**Issue**: "HUGGINGFACE_API_KEY not found"
- **Solution**: Make sure you've created a `.env` file and added your API key

**Issue**: OCR not working on scanned PDFs
- **Solution**: Ensure the image quality is good. Try using `.jpg` or `.png` format directly

**Issue**: Slow response times
- **Solution**: Hugging Face API can be slow on free tier. Consider:
  - Reducing `TOP_K_RETRIEVAL` in `.env`
  - Using smaller documents
  - Upgrading to Hugging Face Pro

**Issue**: Translation not working
- **Solution**: Some language pairs may not have pre-trained models. The system falls back to English.

**Issue**: Out of memory errors
- **Solution**: 
  - Reduce `CHUNK_SIZE` in `.env`
  - Process fewer documents at once
  - Use smaller files

---

## ğŸš€ Performance Tips

1. **Optimize Chunk Size**: Adjust `CHUNK_SIZE` based on your documents
   - Technical docs: 300-500 words
   - Narratives: 500-800 words

2. **Batch Processing**: Process multiple small documents together for efficiency

3. **Cache Results**: The system maintains embeddings in memory during the session

4. **Use Specific Questions**: More specific questions get better answers

5. **Enable Translation Selectively**: Disable translation for English-only workflows

---

## ğŸ”® Future Enhancements (V2)

- [ ] Real-time collaboration (multi-user chat)
- [ ] Voice input via Speech-to-Text
- [ ] Export Q&A logs to PDF
- [ ] Document version comparison
- [ ] Knowledge graph visualization with NetworkX
- [ ] Local model support (no API required)
- [ ] Custom model fine-tuning
- [ ] Batch document processing API
- [ ] Advanced analytics dashboard
- [ ] Plugin system for custom document types

---

## ğŸ¤ Contributing

Contributions are welcome! Please feel free to submit a Pull Request.

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

---

## ğŸ“„ License

This project is licensed under the MIT License - see the LICENSE file for details.

---

## ğŸ™ Acknowledgments

- [Hugging Face](https://huggingface.co/) for providing amazing models and APIs
- [LangChain](https://langchain.com/) for the RAG framework
- [Gradio](https://gradio.app/) for the UI framework
- [FAISS](https://github.com/facebookresearch/faiss) by Facebook Research for vector search

---

## ï¿½ Project Structure

The project is now organized into clean folders:

```
rag/
â”œâ”€â”€ ğŸ“„ Core Application (Python files in root)
â”‚   â”œâ”€â”€ app.py                    # Main Gradio application
â”‚   â”œâ”€â”€ rag_engine.py            # RAG engine with embeddings & LLM
â”‚   â”œâ”€â”€ pipeline.py              # Document processing
â”‚   â”œâ”€â”€ multilingual.py          # Multilingual support
â”‚   â””â”€â”€ advanced_features.py     # OCR, PII detection, etc.
â”‚
â”œâ”€â”€ ğŸ“š Documentation (docs/)
â”‚   â”œâ”€â”€ QUICKSTART.md            # Quick 5-minute setup
â”‚   â”œâ”€â”€ INSTALLATION.md          # Detailed installation
â”‚   â”œâ”€â”€ COMPETITIVE_ADVANTAGES.md # Why RAG vs GPT-4/Claude/Perplexity
â”‚   â”œâ”€â”€ FAQ_2025.md              # Comprehensive Q&A
â”‚   â”œâ”€â”€ TECHNICAL_SPECIFICATIONS.md
â”‚   â””â”€â”€ [More documentation...]
â”‚
â””â”€â”€ ğŸ§ª Tests (tests/)
    â”œâ”€â”€ test_llm.py              # LLM tests
    â””â”€â”€ test_setup.py            # Setup verification
```

**See [PROJECT_STRUCTURE.md](PROJECT_STRUCTURE.md) for complete file organization.**

### ğŸ“– Documentation Quick Links

- **New users?** â†’ [docs/QUICKSTART.md](docs/QUICKSTART.md)
- **Need to pitch/sell?** â†’ [docs/COMPETITIVE_ADVANTAGES.md](docs/COMPETITIVE_ADVANTAGES.md) â­
- **Technical details?** â†’ [docs/TECHNICAL_SPECIFICATIONS.md](docs/TECHNICAL_SPECIFICATIONS.md)
- **All documentation** â†’ [docs/README.md](docs/README.md)

---

## ï¿½ğŸ“ Support

For issues and questions:
- Open an issue on GitHub
- Check the troubleshooting section in [docs/FAQ_2025.md](docs/FAQ_2025.md)
- Review Hugging Face API documentation

---

## âš ï¸ Disclaimer

This application uses Hugging Face's API and requires an active internet connection. Response times and quality depend on:
- API availability and rate limits
- Model performance
- Document complexity
- Network speed

For production use, consider:
- Upgrading to Hugging Face Pro
- Implementing local models
- Adding caching layers
- Rate limiting and error handling

---

## ğŸ“Š Example Screenshots

### Document Upload & Processing
Upload any document and get instant classification, language detection, and insights.

### Multilingual Chat Interface
Ask questions in your native language and get accurate answers with source citations.

### Auto-Generated Questions
Smart question suggestions based on document content and type.

### Document Insights
Automatic summaries, key points, and statistics for quick understanding.

---

**Built with â¤ï¸ using LangChain + Hugging Face**

*Making documents accessible and conversational in every language!*
