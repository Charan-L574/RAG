# ğŸ“„ SmartDoc Analyst

> **Intelligent multi-format document analysis platform powered by RAG (Retrieval-Augmented Generation)**

Ask questions about your documents in natural language and get accurate answers with source citations. Supports PDFs, Word, Excel, PowerPoint, and images in 50+ languages.

---

## âœ¨ Features

- **ğŸ” Multi-Format Support** - Upload PDFs, DOCX, Excel, PowerPoint, CSV, and images
- **ğŸ’¬ Intelligent Q&A** - Ask questions in natural language, get context-aware answers
- **ğŸ“š Source Citations** - Every answer includes exact document and page references
- **ğŸŒ Multilingual** - Supports 50+ languages including Hindi, Spanish, French, Chinese, and more
- **ğŸš€ Semantic Caching** - 38% faster responses for similar queries
- **ğŸ¯ Auto-Classification** - Automatically categorizes documents (Resume, Legal, Financial, etc.)
- **âš¡ Advanced Features** - Query expansion, confidence scoring, multi-hop reasoning
- **ğŸ”’ Accurate & Transparent** - RAG architecture prevents hallucinations with source grounding

---

## ğŸ› ï¸ Tech Stack

- **LangChain** - Document processing & RAG pipeline
- **FAISS** - Vector database for semantic search
- **Meta-Llama-3-8B** - Large language model via HuggingFace API
- **sentence-transformers** - Multilingual embeddings (384 dimensions)
- **Gradio** - Web interface
- **HuggingFace API** - AI infrastructure (100% API-based, no GPU needed)

---

## ğŸš€ Quick Start

### 1. Clone Repository
```bash
git clone https://github.com/Charan-L574/RAG.git
cd RAG
```

### 2. Install Dependencies
```bash
python -m venv .venv
.venv\Scripts\activate  # Windows
# source .venv/bin/activate  # Linux/Mac

pip install -r requirements.txt
```

### 3. Setup Environment
Create `.env` file with your HuggingFace API key:
```env
HUGGINGFACE_API_KEY=your_api_key_here
```

Get free API key: [https://huggingface.co/settings/tokens](https://huggingface.co/settings/tokens)

### 4. Run Application
```bash
python app_enhanced_langchain.py
```

Open browser at `http://localhost:7860`

---

## ğŸ“– Usage

### 1. Upload Documents
- Drag & drop or select files (PDF, DOCX, Excel, PPTX, Images)
- Click **"Classify Documents"** to auto-detect document types
- Click **"ğŸš€ Process Documents"** to ingest into system

### 2. Ask Questions
- Type your question in natural language
- Get AI-generated answers with source citations
- View confidence scores and related documents

### 3. Advanced Features
- **Interview Questions** - Generate questions from resumes/job descriptions
- **Career Options** - Get career suggestions based on resume analysis
- **Multilingual** - Ask and answer in 50+ languages
- **Document Comparison** - Compare multiple documents side-by-side

---

## ğŸ¯ Use Cases

- **HR & Recruitment** - Screen resumes, match candidates to job descriptions
- **Academic Research** - Analyze research papers, extract key findings
- **Legal Review** - Search contracts, find specific clauses
- **Business Intelligence** - Query reports, analyze trends across documents
- **Personal Knowledge Base** - Organize and search personal documents

---

## ğŸ“Š Key Metrics

| Metric | Value |
|--------|-------|
| Embedding Dimensions | 384 |
| Supported Languages | 50+ |
| Document Formats | 6+ |
| Cache Hit Rate | 38% |
| LLM Parameters | 8 billion |
| Context Window | 8,192 tokens |
| Response Time | ~2 seconds |

---

## ğŸ—ï¸ Architecture

```
Documents â†’ LangChain Loaders â†’ Text Chunks (600 chars)
    â†“
Sentence Transformers â†’ Embeddings (384 dims) â†’ FAISS Index
    â†“
User Query â†’ Semantic Search â†’ Top-5 Relevant Chunks
    â†“
Llama-3 LLM â†’ Context-Aware Answer â†’ Source Citations
```

**RAG Pipeline:** Retrieval â†’ Augmentation â†’ Generation

---

## ğŸ“ Project Structure

```
RAG/
â”œâ”€â”€ app_enhanced_langchain.py    # Main application
â”œâ”€â”€ pipeline.py                   # Document processing
â”œâ”€â”€ requirements.txt              # Dependencies
â”œâ”€â”€ .env                         # API keys (create this)
â””â”€â”€ docs/
    â””â”€â”€ ARCHITECTURE.md          # Technical documentation
```

---

## ğŸ”§ Configuration

Edit these parameters in `app_enhanced_langchain.py`:

```python
chunk_size = 600              # Characters per chunk
chunk_overlap = 200           # Overlap between chunks
top_k = 5                     # Number of chunks to retrieve
temperature = 0.3             # LLM creativity (0-1)
cache_threshold = 0.95        # Semantic cache similarity
```

---

## ğŸ“ Requirements

- Python 3.8+
- HuggingFace API key (free tier available)
- 2GB RAM minimum
- Internet connection (for API calls)

---

## ğŸ¤ Contributing

Contributions welcome! Please:
1. Fork the repository
2. Create a feature branch
3. Commit your changes
4. Push and create a Pull Request

---

## ğŸ“„ License

MIT License - See LICENSE file for details

---

## ğŸ‘¨â€ğŸ’» Author

**Charan**  
GitHub: [@Charan-L574](https://github.com/Charan-L574)

---

## ğŸ™ Acknowledgments

- Meta AI for Llama-3 model
- HuggingFace for inference infrastructure
- LangChain community for RAG framework
- Facebook AI for FAISS vector search

---

## ğŸ“ Support

- **Issues:** [GitHub Issues](https://github.com/Charan-L574/RAG/issues)
- **Discussions:** [GitHub Discussions](https://github.com/Charan-L574/RAG/discussions)

---

<div align="center">

**â­ Star this repo if you find it useful!**

Made with â¤ï¸ using RAG & AI

</div>
